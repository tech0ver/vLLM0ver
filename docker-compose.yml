name: vllms

x-base-vllm: &base-vllm
  image: vllm/vllm-openai:${VLLM_TAG:-v0.8.2}
  shm_size: 4g
  gpus: all
  environment:
    HUGGING_FACE_HUB_TOKEN: ${HUGGING_FACE_HUB_TOKEN}
    HF_HUB_ENABLE_HF_TRANSFER: 0
    HF_HUB_DISABLE_TELEMETRY: 1
  volumes:
    - hf_cache:/root/.cache/huggingface
  networks:
    - vllms_net
  depends_on:
    - proxy

services:
  proxy:
    image: nginx:${NGINX_TAG:-1.27-alpine}
    volumes:
      - ./docker/nginx.conf:/etc/nginx/nginx.conf:ro
    ports:
      - "8080:8080"
    networks:
      - vllms_net

  qwen2.5-0.5b:
    <<: *base-vllm
    command:
      - --task=generate
      - --model=Qwen/Qwen2.5-0.5B-Instruct-GPTQ-Int4

  user-bge-m3:
    <<: *base-vllm
    command:
      - --task=embed
      - --model=deepvk/USER-bge-m3

volumes:
  hf_cache:

networks:
  vllms_net:
    name: vllms_net
